{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago Taxi + Weather Data Integration & Modeling\n",
    "**Purpose**: Combine taxi trips with weather data and create normalized data model  \n",
    "**Input**: Raw taxi data + weather data from APIs  \n",
    "**Output**: AWS-optimized dataset with master tables for efficient storage/querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json\n",
    "\n",
    "# Display settings for better data exploration\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "\n",
    "print(\"Chicago Taxi-Weather Integration Pipeline Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Taxi Data from Chicago Open Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical date (2 months ago) for consistent data timeframe\n",
    "target_date = datetime.now() - relativedelta(months=2)\n",
    "date_str = target_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Chicago Taxi Trips API configuration\n",
    "DATASET_ID = \"ajtu-isnz\"\n",
    "BASE_URL = f\"https://data.cityofchicago.org/resource/{DATASET_ID}.json\"\n",
    "\n",
    "# Build query for full day of taxi trips\n",
    "where_clause = (\n",
    "    f\"trip_start_timestamp >= '{date_str}T00:00:00' \"\n",
    "    f\"AND trip_start_timestamp <= '{date_str}T23:59:59'\"\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"$where\": where_clause,\n",
    "    \"$limit\": 30000,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"X-App-Token\": os.environ.get(\"CHICAGO_API_TOKEN\", \"\")\n",
    "}\n",
    "\n",
    "print(f\"Fetching taxi data for: {date_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch taxi trips from API\n",
    "response = requests.get(BASE_URL, headers=headers, params=params, timeout=60)\n",
    "response.raise_for_status()\n",
    "taxi_data = response.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "taxi_trips = pd.DataFrame(taxi_data)\n",
    "\n",
    "print(f\"Taxi records loaded: {len(taxi_trips):,}\")\n",
    "print(f\"Columns: {len(taxi_trips.columns)}\")\n",
    "taxi_trips.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove complex nested columns that cause join issues\n",
    "columns_to_drop = [\n",
    "    \"pickup_centroid_location\", \n",
    "    \"dropoff_centroid_location\",\n",
    "    \"pickup_census_tract\", \n",
    "    \"dropoff_census_tract\"\n",
    "]\n",
    "\n",
    "taxi_trips.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "print(f\"Dropped complex columns: {columns_to_drop}\")\n",
    "\n",
    "# Remove rows with missing critical data\n",
    "before_cleanup = len(taxi_trips)\n",
    "taxi_trips.dropna(inplace=True)\n",
    "after_cleanup = len(taxi_trips)\n",
    "\n",
    "print(f\"Rows removed due to missing data: {before_cleanup - after_cleanup:,}\")\n",
    "print(f\"Clean taxi records: {after_cleanup:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "taxi_trips.rename(columns={\n",
    "    \"pickup_community_area\": \"pickup_community_area_id\",\n",
    "    \"dropoff_community_area\": \"dropoff_community_area_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Create weather correlation column (round trip start time to nearest hour)\n",
    "taxi_trips[\"datetime_for_weather\"] = pd.to_datetime(\n",
    "    taxi_trips[\"trip_start_timestamp\"]\n",
    ").dt.floor(\"h\")\n",
    "\n",
    "print(\"Taxi data prepared for weather correlation\")\n",
    "print(f\"Date range for weather join: {taxi_trips['datetime_for_weather'].min()} to {taxi_trips['datetime_for_weather'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Weather Data from Open-Meteo API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch weather data for the same date as taxi data\n",
    "CHICAGO_LAT = 41.85\n",
    "CHICAGO_LON = -87.65\n",
    "\n",
    "weather_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "weather_params = {\n",
    "    \"latitude\": CHICAGO_LAT,\n",
    "    \"longitude\": CHICAGO_LON,\n",
    "    \"start_date\": date_str,\n",
    "    \"end_date\": date_str,\n",
    "    \"hourly\": \"temperature_2m,wind_speed_10m,rain,precipitation\"\n",
    "}\n",
    "\n",
    "weather_response = requests.get(weather_url, params=weather_params)\n",
    "weather_response.raise_for_status()\n",
    "weather_data = weather_response.json()\n",
    "\n",
    "# Create weather DataFrame\n",
    "weather_df = pd.DataFrame({\n",
    "    \"datetime\": pd.to_datetime(weather_data[\"hourly\"][\"time\"]),\n",
    "    \"temperature\": weather_data[\"hourly\"][\"temperature_2m\"],\n",
    "    \"wind_speed\": weather_data[\"hourly\"][\"wind_speed_10m\"],\n",
    "    \"rain\": weather_data[\"hourly\"][\"rain\"],\n",
    "    \"precipitation\": weather_data[\"hourly\"][\"precipitation\"]\n",
    "})\n",
    "\n",
    "print(f\"Weather records loaded: {len(weather_df)}\")\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Join Taxi and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge taxi trips with weather data based on hourly timestamps\n",
    "taxi_with_weather = taxi_trips.merge(\n",
    "    weather_df,\n",
    "    left_on=\"datetime_for_weather\",\n",
    "    right_on=\"datetime\",\n",
    "    how=\"inner\"  # Only keep trips with matching weather data\n",
    ")\n",
    "\n",
    "print(f\"Successfully joined taxi-weather records: {len(taxi_with_weather):,}\")\n",
    "print(f\"Join rate: {len(taxi_with_weather)/len(taxi_trips)*100:.1f}%\")\n",
    "\n",
    "# Show sample of joined data\n",
    "taxi_with_weather.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Type Optimization for AWS Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize data types to reduce memory usage and improve AWS performance\n",
    "memory_before = taxi_with_weather.memory_usage(deep=True).sum()\n",
    "\n",
    "# Define optimized data types\n",
    "optimized_types = {\n",
    "    \"trip_end_timestamp\": \"datetime64[ns]\",\n",
    "    \"trip_seconds\": \"int32\",\n",
    "    \"trip_miles\": \"float32\",\n",
    "    \"pickup_community_area_id\": \"int8\",\n",
    "    \"dropoff_community_area_id\": \"int8\",\n",
    "    \"fare\": \"float32\",\n",
    "    \"tips\": \"float32\",\n",
    "    \"tolls\": \"float32\",\n",
    "    \"extras\": \"float32\",\n",
    "    \"trip_total\": \"float32\",\n",
    "    \"temperature\": \"float32\",\n",
    "    \"wind_speed\": \"float32\",\n",
    "    \"rain\": \"float32\",\n",
    "    \"precipitation\": \"float32\"\n",
    "}\n",
    "\n",
    "# Apply optimizations where columns exist\n",
    "for col, dtype in optimized_types.items():\n",
    "    if col in taxi_with_weather.columns:\n",
    "        try:\n",
    "            taxi_with_weather[col] = taxi_with_weather[col].astype(dtype)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not convert {col}: {e}\")\n",
    "\n",
    "memory_after = taxi_with_weather.memory_usage(deep=True).sum()\n",
    "savings = (1 - memory_after/memory_before) * 100\n",
    "\n",
    "print(f\"Memory optimization: {savings:.1f}% reduction\")\n",
    "print(f\"Before: {memory_before/1024/1024:.1f} MB\")\n",
    "print(f\"After: {memory_after/1024/1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Normalized Master Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Payment Type Master Table\n",
    "payment_types = taxi_with_weather[\"payment_type\"].drop_duplicates().reset_index(drop=True)\n",
    "payment_type_master = pd.DataFrame({\n",
    "    \"payment_type_id\": range(1, len(payment_types) + 1),\n",
    "    \"payment_type\": payment_types\n",
    "})\n",
    "\n",
    "print(f\"Payment types identified: {len(payment_type_master)}\")\n",
    "payment_type_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Company Master Table\n",
    "companies = taxi_with_weather[\"company\"].drop_duplicates().reset_index(drop=True)\n",
    "company_master = pd.DataFrame({\n",
    "    \"company_id\": range(1, len(companies) + 1),\n",
    "    \"company\": companies\n",
    "})\n",
    "\n",
    "print(f\"Taxi companies identified: {len(company_master)}\")\n",
    "company_master.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Final Normalized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join master tables to create normalized fact table\n",
    "taxi_final = taxi_with_weather.merge(payment_type_master, on=\"payment_type\")\n",
    "taxi_final = taxi_final.merge(company_master, on=\"company\")\n",
    "\n",
    "# Remove original text columns (now replaced with IDs)\n",
    "taxi_final.drop([\"payment_type\", \"company\"], axis=1, inplace=True)\n",
    "\n",
    "print(f\"Final normalized dataset: {len(taxi_final):,} records\")\n",
    "print(f\"Columns: {len(taxi_final.columns)}\")\n",
    "\n",
    "# Calculate final memory savings\n",
    "original_memory = taxi_with_weather.memory_usage(deep=True).sum()\n",
    "final_memory = taxi_final.memory_usage(deep=True).sum()\n",
    "total_savings = (1 - final_memory/original_memory) * 100\n",
    "\n",
    "print(f\"Total memory optimization: {total_savings:.1f}% reduction\")\n",
    "taxi_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export Data for AWS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"csv/processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Export fact table\n",
    "fact_table_path = f\"{output_dir}/chicago_taxi_weather_fact.csv\"\n",
    "taxi_final.to_csv(fact_table_path, index=False)\n",
    "print(f\"Fact table saved: {fact_table_path}\")\n",
    "\n",
    "# Export master tables\n",
    "payment_master_path = f\"{output_dir}/payment_type_master.csv\"\n",
    "payment_type_master.to_csv(payment_master_path, index=False)\n",
    "print(f\"Payment master saved: {payment_master_path}\")\n",
    "\n",
    "company_master_path = f\"{output_dir}/company_master.csv\"\n",
    "company_master.to_csv(company_master_path, index=False)\n",
    "print(f\"Company master saved: {company_master_path}\")\n",
    "\n",
    "print(\"\\n=== CHICAGO TAXI-WEATHER PIPELINE COMPLETE ===\")\n",
    "print(f\"Total records processed: {len(taxi_final):,}\")\n",
    "print(f\"Memory optimized by: {total_savings:.1f}%\")\n",
    "print(\"Ready for AWS ingestion!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}